{
 "cells": [
  {
   "cell_type": "code",
   "id": "8b8c8dd27e740f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T09:30:59.850354Z",
     "start_time": "2025-02-02T09:30:58.834458Z"
    }
   },
   "source": [
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "from rdflib import Graph\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "# 1. 加载 RDF 图数据\n",
    "def load_rdf_data():\n",
    "    graphs = []\n",
    "    try:\n",
    "        g1 = Graph()\n",
    "        g1.parse(\n",
    "            \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/AIFB.n3\",\n",
    "            format=\"n3\")\n",
    "        graphs.append(g1)\n",
    "\n",
    "        # g2 = Graph()\n",
    "        # g2.parse(\n",
    "        #     \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/BGS.nt\",\n",
    "        #     format=\"nt\")\n",
    "        # graphs.append(g2)\n",
    "        #\n",
    "        # g3 = Graph()\n",
    "        # g3.parse(\n",
    "        #     \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/wikidata-20250117-lexeme-BETA.nt\",\n",
    "        #     format=\"nt\")\n",
    "        # graphs.append(g3)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing RDF files: {e}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "# 2. 使用图遍历生成路径序列 (广度优先搜索)\n",
    "def generate_graph_walks(graphs, depth=8):\n",
    "    walks = []\n",
    "    for graph in graphs:\n",
    "        nx_graph = nx.DiGraph()\n",
    "        for subj, pred, obj in graph:\n",
    "            nx_graph.add_edge(str(subj), str(obj), label=str(pred))  # 记录边的label\n",
    "\n",
    "        for node in nx_graph.nodes:\n",
    "            queue = [(node, [node])]  # (当前节点，路径)\n",
    "            for _ in range(depth):\n",
    "                next_queue = []\n",
    "                for current, path in queue:\n",
    "                    neighbors = list(nx_graph.neighbors(current))\n",
    "                    for neighbor in neighbors:\n",
    "                        edge_label = nx_graph[current][neighbor]['label']  # 获取边的label\n",
    "\n",
    "                        # 将边的label插入路径中\n",
    "                        new_path = path + [edge_label, neighbor]\n",
    "                        next_queue.append((neighbor, new_path))\n",
    "\n",
    "                        # 确保路径长度到达 depth 时才存储\n",
    "                        if len(new_path) == (2 * depth - 1):  # 节点+边交替，长度为2*depth-1\n",
    "                            walks.append(new_path)\n",
    "\n",
    "                queue = next_queue\n",
    "    return walks\n",
    "\n",
    "\n",
    "# 3. 使用 Weisfeiler-Lehman 子树算法生成路径\n",
    "def generate_wl_subtree_walks(graphs, iterations=4, depth=2):\n",
    "    walks = []\n",
    "    for graph in graphs:\n",
    "        nx_graph = nx.DiGraph()\n",
    "        for subj, pred, obj in graph:\n",
    "            nx_graph.add_edge(str(subj), str(obj), label=str(pred))\n",
    "\n",
    "        for node in nx_graph.nodes:\n",
    "            paths = [[node]]\n",
    "            for _ in range(iterations):\n",
    "                new_paths = []\n",
    "                for path in paths:\n",
    "                    if len(path) < depth:\n",
    "                        neighbors = list(nx_graph.neighbors(path[-1]))\n",
    "                        for neighbor in neighbors:\n",
    "                            new_paths.append(path + [neighbor])\n",
    "                paths.extend(new_paths)\n",
    "            walks.extend(paths)\n",
    "    return walks\n",
    "\n",
    "\n",
    "# 4. 使用 CBOW 生成嵌入\n",
    "def train_word2vec(walks, dimensions=200, window_size=5, sg=0, negative=25, epochs=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=walks,\n",
    "        vector_size=dimensions,\n",
    "        window=window_size,\n",
    "        sg=sg,\n",
    "        negative=negative,\n",
    "        epochs=epochs,\n",
    "        workers=4\n",
    "    )\n",
    "    for i in range(10):  # 进行 10 轮手动迭代\n",
    "        model.train(walks, total_examples=len(walks), epochs=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 3. 使用 Skip-gram 模型生成嵌入\n",
    "def train_skipgram_model(walks, dimensions=200, window_size=5, sg=1, negative=25, epochs=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=walks,\n",
    "        vector_size=dimensions,\n",
    "        window=window_size,\n",
    "        sg=sg,  # 使用 Skip-gram\n",
    "        negative=negative,\n",
    "        epochs=epochs,\n",
    "        workers=4\n",
    "    )\n",
    "    for i in range(10):  # 进行 10 轮手动迭代\n",
    "        model.train(walks, total_examples=len(walks), epochs=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 5. 特征提取\n",
    "def extract_features(model, nodes):\n",
    "    features = {node: model.wv[node] for node in nodes if node in model.wv}\n",
    "    return features\n",
    "\n",
    "\n",
    "# 6. 分类/回归任务\n",
    "def evaluate_features(features, labels, task=\"classification\"):\n",
    "    X = list(features.values())\n",
    "    y = [labels.get(node, 0) for node in features.keys()]\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    if task == \"classification\":\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "    accuracies = []\n",
    "    rmses = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            accuracies.append(accuracy_score(y_test, predictions))\n",
    "        else:\n",
    "            rmses.append(mean_squared_error(y_test, predictions, squared=False))\n",
    "\n",
    "    if task == \"classification\":\n",
    "        print(\"Average Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "    else:\n",
    "        print(\"Average RMSE:\", sum(rmses) / len(rmses))\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T09:31:00.451270Z",
     "start_time": "2025-02-02T09:30:59.855905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "graphs = load_rdf_data()\n",
    "print(\"RDF 数据加载完成！\")"
   ],
   "id": "8106ac63c3f06b06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF 数据加载完成！\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T09:31:00.539010Z",
     "start_time": "2025-02-02T09:31:00.536962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for graph in graphs:\n",
    "    print(graph)\n",
    "    break\n",
    "\n",
    "\n"
   ],
   "id": "23836b554658dff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a rdfg:Graph;rdflib:storage [a rdflib:Store;rdfs:label 'Memory']].\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T09:31:00.630153Z",
     "start_time": "2025-02-02T09:31:00.544009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "graph = graphs[0]\n",
    "\n",
    "# 转换为三元组列表\n",
    "triples = list(graph)\n",
    "\n",
    "# 随机采样 100 个三元组\n",
    "sampled_triples = random.sample(triples, 1500)\n",
    "\n",
    "# 创建新的图对象，并添加采样的三元组\n",
    "sampled_graph = Graph()\n",
    "for triple in sampled_triples:\n",
    "    sampled_graph.add(triple)\n",
    "\n",
    "# 不覆盖原始 graphs\n",
    "sampled_graphs = [sampled_graph]\n"
   ],
   "id": "1502ae1da63dd2b9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import random\n",
    "graph = graphs[0]\n",
    "\n",
    "# 转换为三元组列表\n",
    "triples = list(graph)\n",
    "\n",
    "# 随机采样 100 个三元组\n",
    "sampled_triples = random.sample(triples, 1500)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "for train_index, test_index in kf.split(sampled_triples):\n",
    "    train_graph_list, test_graph_list = [sampled_triples[i] for i in train_index], [sampled_triples[i] for i in test_index]\n",
    "    train_graph = Graph()\n",
    "\n",
    "# 添加采样的三元组\n",
    "    for triple in train_graph_list:\n",
    "        train_graph.add(triple)\n",
    "\n",
    "    train_graphs = [train_graph]\n",
    "\n",
    "    bfs_walks = generate_graph_walks(graphs, depth=8)\n",
    "    CBOW_embedding_model = train_word2vec(bfs_walks, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "    print(\"嵌入模型训练完成！\")\n",
    "\n",
    "    train_nodes = [str(node) for graph in train_graphs for node in graph.all_nodes()]\n",
    "    features = extract_features(CBOW_embedding_model, train_nodes)\n",
    "\n"
   ],
   "id": "772ff71c9a92708f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T09:31:00.683912Z",
     "start_time": "2025-02-02T09:31:00.635693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 生成广度优先路径序列\n",
    "bfs_walks = generate_graph_walks(sampled_graphs, depth=8)\n",
    "print(\"广度优先路径序列生成完成！\")"
   ],
   "id": "a58bc6d066241318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广度优先路径序列生成完成！\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:55:59.931870Z",
     "start_time": "2025-01-31T10:55:59.921399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 生成 Weisfeiler-Lehman 子树路径序列\n",
    "wl_walks = generate_wl_subtree_walks(graphs, iterations=4, depth=2)\n",
    "print(\"Weisfeiler-Lehman 子树路径序列生成完成！\")"
   ],
   "id": "10c6cac37cd3c2d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weisfeiler-Lehman 子树路径序列生成完成！\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:06.357078Z",
     "start_time": "2025-01-31T10:55:59.941685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "for train_index, test_index in kf.split(nodes):\n",
    "\n",
    "        X_train, X_test = [bfs_walks[i] for i in train_index], [bfs_walks[i] for i in test_index]\n",
    "        bfs_walks = generate_graph_walks(X_train, depth=8)\n",
    "        CBOW_embedding_model = train_word2vec(bfs_walks, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "        print(\"嵌入模型训练完成！\")\n",
    "\n",
    "        nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "        features = extract_features(CBOW_embedding_model, nodes)\n"
   ],
   "id": "9755050d69b36ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:06.366487Z",
     "start_time": "2025-01-31T10:56:06.364762Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "221e97b5a55cadd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:06.999881Z",
     "start_time": "2025-01-31T10:56:06.379073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练嵌入模型\n",
    "CBOW_embedding_model = train_word2vec(X_train, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "print(\"嵌入模型训练完成！\")"
   ],
   "id": "c2a8ae3211a68826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:08.567365Z",
     "start_time": "2025-01-31T10:56:07.015842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练 Skip-gram 嵌入模型\n",
    "SG_embedding_model = train_skipgram_model(bfs_walks, dimensions=200, window_size=5, sg=1, negative=25)\n",
    "print(\"Skip-gram 嵌入模型训练完成！\")"
   ],
   "id": "76f0cfed136c65d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram 嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:08.576804Z",
     "start_time": "2025-01-31T10:56:08.570380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 提取嵌入特征\n",
    "nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "features = extract_features(SG_embedding_model, nodes)\n",
    "print(\"嵌入特征提取完成！\")"
   ],
   "id": "6bd182251e39fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入特征提取完成！\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T10:56:09.028148Z",
     "start_time": "2025-01-31T10:56:08.584064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 评估分类任务\n",
    "labels = {\"node1\": 0, \"node2\": 1}  # 替换为你的节点标签\n",
    "evaluate_features(features, labels, task=\"classification\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
