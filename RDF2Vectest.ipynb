{
 "cells": [
  {
   "cell_type": "code",
   "id": "8b8c8dd27e740f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:38.155942Z",
     "start_time": "2025-02-03T15:04:37.301845Z"
    }
   },
   "source": [
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "from rdflib import Graph\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "# 1. 加载 RDF 图数据\n",
    "def load_rdf_data():\n",
    "    graphs = []\n",
    "    try:\n",
    "        g1 = Graph()\n",
    "        g1.parse(\n",
    "            \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/AIFB.n3\",\n",
    "            format=\"n3\")\n",
    "        graphs.append(g1)\n",
    "\n",
    "        # g2 = Graph()\n",
    "        # g2.parse(\n",
    "        #     \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/BGS.nt\",\n",
    "        #     format=\"nt\")\n",
    "        # graphs.append(g2)\n",
    "        #\n",
    "        # g3 = Graph()\n",
    "        # g3.parse(\n",
    "        #     \"/Users/yingji/Library/CloudStorage/OneDrive-MicrosoftOffice365/VU_course/AI_master/ML for Graph/RDF2Vec/dataset/wikidata-20250117-lexeme-BETA.nt\",\n",
    "        #     format=\"nt\")\n",
    "        # graphs.append(g3)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing RDF files: {e}\")\n",
    "    return graphs\n",
    "\n",
    "\n",
    "# 2. 使用图遍历生成路径序列 (广度优先搜索)\n",
    "def generate_graph_walks(graphs, depth=10):  # 增加默认深度\n",
    "    walks = []\n",
    "    for graph in graphs:\n",
    "        nx_graph = nx.DiGraph()\n",
    "        for subj, pred, obj in graph:\n",
    "            nx_graph.add_edge(str(subj), str(obj), label=str(pred))\n",
    "\n",
    "        visited = set()\n",
    "\n",
    "        # 遍历每个节点，确保所有节点被访问\n",
    "        for node in nx_graph.nodes:\n",
    "            if node not in visited:\n",
    "                queue = [(node, [node])]\n",
    "                visited.add(node)\n",
    "\n",
    "                for _ in range(depth):\n",
    "                    next_queue = []\n",
    "                    for current, path in queue:\n",
    "                        neighbors = list(nx_graph.neighbors(current))\n",
    "\n",
    "                        # 如果没有邻居，确保孤立节点也被记录\n",
    "                        if not neighbors and len(path) == 1:\n",
    "                            walks.append(path)\n",
    "\n",
    "                        for neighbor in neighbors:\n",
    "                            new_path = path + [neighbor]\n",
    "                            next_queue.append((neighbor, new_path))\n",
    "\n",
    "                            if len(new_path) == depth:\n",
    "                                walks.append(new_path)\n",
    "                            visited.add(neighbor)\n",
    "                    queue = next_queue\n",
    "\n",
    "        # 处理孤立节点（无入度和出度的节点）\n",
    "        isolated_nodes = set(nx_graph.nodes) - visited\n",
    "        for isolated_node in isolated_nodes:\n",
    "            walks.append([isolated_node])\n",
    "\n",
    "    return walks\n",
    "\n",
    "\n",
    "# 3. 使用 Weisfeiler-Lehman 子树算法生成路径\n",
    "def generate_wl_subtree_walks(graphs, iterations=4, depth=2):\n",
    "    walks = []\n",
    "    for graph in graphs:\n",
    "        nx_graph = nx.DiGraph()\n",
    "        for subj, pred, obj in graph:\n",
    "            nx_graph.add_edge(str(subj), str(obj), label=str(pred))\n",
    "\n",
    "        for node in nx_graph.nodes:\n",
    "            paths = [[node]]\n",
    "            for _ in range(iterations):\n",
    "                new_paths = []\n",
    "                for path in paths:\n",
    "                    if len(path) < depth:\n",
    "                        neighbors = list(nx_graph.neighbors(path[-1]))\n",
    "                        for neighbor in neighbors:\n",
    "                            new_paths.append(path + [neighbor])\n",
    "                paths.extend(new_paths)\n",
    "            walks.extend(paths)\n",
    "    return walks\n",
    "\n",
    "\n",
    "# 4. 使用 CBOW 生成嵌入\n",
    "def train_word2vec(walks, dimensions=200, window_size=5, sg=0, negative=25, epochs=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=walks,\n",
    "        vector_size=dimensions,\n",
    "        window=window_size,\n",
    "        sg=sg,\n",
    "        negative=negative,\n",
    "        epochs=epochs,\n",
    "        workers=4\n",
    "    )\n",
    "    for i in range(10):  # 进行 10 轮手动迭代\n",
    "        model.train(walks, total_examples=len(walks), epochs=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 3. 使用 Skip-gram 模型生成嵌入\n",
    "def train_skipgram_model(walks, dimensions=200, window_size=5, sg=1, negative=25, epochs=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=walks,\n",
    "        vector_size=dimensions,\n",
    "        window=window_size,\n",
    "        sg=sg,  # 使用 Skip-gram\n",
    "        negative=negative,\n",
    "        epochs=epochs,\n",
    "        workers=4\n",
    "    )\n",
    "    for i in range(10):  # 进行 10 轮手动迭代\n",
    "        model.train(walks, total_examples=len(walks), epochs=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 5. 特征提取\n",
    "def extract_features(model, nodes):\n",
    "    features = [model.wv[node] for node in nodes if node in model.wv]\n",
    "    return features\n",
    "\n",
    "\n",
    "# 6. 分类/回归任务\n",
    "def evaluate_features(features, labels, task=\"classification\"):\n",
    "    X = list(features.values())\n",
    "    y = [labels.get(node, 0) for node in features.keys()]\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    if task == \"classification\":\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        model = RandomForestRegressor()\n",
    "\n",
    "    accuracies = []\n",
    "    rmses = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            accuracies.append(accuracy_score(y_test, predictions))\n",
    "        else:\n",
    "            rmses.append(mean_squared_error(y_test, predictions, squared=False))\n",
    "\n",
    "    if task == \"classification\":\n",
    "        print(\"Average Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "    else:\n",
    "        print(\"Average RMSE:\", sum(rmses) / len(rmses))\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:38.765309Z",
     "start_time": "2025-02-03T15:04:38.161747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "graphs = load_rdf_data()\n",
    "\n",
    "print(\"RDF 数据加载完成！\")"
   ],
   "id": "8106ac63c3f06b06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF 数据加载完成！\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.622736Z",
     "start_time": "2025-02-03T15:04:38.840623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rdflib import Graph, Namespace\n",
    "\n",
    "# # 结果展示\n",
    "# import pandas as pd\n",
    "# import graphs as tools\n",
    "#\n",
    "# affiliation_df = pd.DataFrame(affiliations, columns=[\"Subject\", \"Affiliation\"])\n",
    "# tools.display_dataframe_to_user(\"Affiliation Information\", affiliation_df)\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# 固定随机数种子\n",
    "random.seed(42)\n",
    "\n",
    "graph = graphs[0]\n",
    "\n",
    "# 转换为三元组列表\n",
    "triples = list(graph)\n",
    "sampled_triples = random.sample(triples, 1500)\n",
    "sampled_graph = Graph()\n",
    "for triple in sampled_triples:\n",
    "    sampled_graph.add(triple)\n",
    "\n",
    "# 随机采样 100 个三元组\n",
    "sampled_graphs = [sampled_graph]\n",
    "# 定义命名空间（假设 affiliation 属于 swrc 命名空间）\n",
    "SWRC = Namespace(\"http://swrc.ontoware.org/ontology#\")\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "for train_index, test_index in kf.split(sampled_triples):\n",
    "    train_graph_list, test_graph_list = [sampled_triples[i] for i in train_index], [sampled_triples[i] for i in test_index]\n",
    "    train_graph = Graph()\n",
    "\n",
    "    for triple in train_graph_list:\n",
    "        train_graph.add(triple)\n",
    "    train_graphs = [train_graph]\n",
    "\n",
    "    test_graph = Graph()\n",
    "\n",
    "    for triple in test_graph_list:\n",
    "        test_graph.add(triple)\n",
    "    test_graphs = [test_graph]\n",
    "\n",
    "    bfs_walks = generate_graph_walks(train_graphs, depth=8)\n",
    "    print(\"bfs_walks完成！\")\n",
    "\n",
    "\n",
    "    CBOW_embedding_model = train_word2vec(bfs_walks, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "    print(\"嵌入模型训练完成！\")\n",
    "\n",
    "    affiliations = []\n",
    "    for s, p, o in train_graph:\n",
    "        if p == SWRC.affiliation:\n",
    "            affiliations.append([s, o])\n",
    "    X_train_nodes = [str(item[0]) for item in affiliations]\n",
    "    Y_train_nodes = [str(item[1]) for item in affiliations]\n",
    "\n",
    "\n",
    "    # 提取所有在 bfs_walks 中出现过的节点\n",
    "    visited_nodes = set(node for walk in bfs_walks for node in walk)\n",
    "    # 同步过滤未遍历的节点和对应标签\n",
    "    filtered_X_train_nodes = []\n",
    "    filtered_Y_train_nodes = []\n",
    "\n",
    "    for x_node, y_node in zip(X_train_nodes, Y_train_nodes):\n",
    "        if x_node in visited_nodes:\n",
    "            filtered_X_train_nodes.append(x_node)\n",
    "            filtered_Y_train_nodes.append(y_node)\n",
    "\n",
    "    X_train_features = extract_features(CBOW_embedding_model, filtered_X_train_nodes)\n",
    "    Y_train_features = extract_features(CBOW_embedding_model, filtered_Y_train_nodes)\n",
    "\n",
    "    affiliations = []\n",
    "    for s, p, o in test_graph:\n",
    "        if p == SWRC.affiliation:\n",
    "            affiliations.append([s, o])\n",
    "    X_test_nodes = [str(item[0]) for item in affiliations]\n",
    "    Y_test_nodes = [str(item[1]) for item in affiliations]\n",
    "\n",
    "    # 测试阶段的同样处理\n",
    "    visited_test_nodes = set(node for walk in bfs_walks for node in walk)\n",
    "    filtered_X_test_nodes = []\n",
    "    filtered_Y_test_nodes = []\n",
    "\n",
    "    for x_node, y_node in zip(X_test_nodes, Y_test_nodes):\n",
    "        if x_node in visited_test_nodes:\n",
    "            filtered_X_test_nodes.append(x_node)\n",
    "            filtered_Y_test_nodes.append(y_node)\n",
    "\n",
    "    X_test_features = extract_features(CBOW_embedding_model, filtered_X_test_nodes)\n",
    "    Y_test_features = extract_features(CBOW_embedding_model, filtered_Y_test_nodes)\n",
    "\n",
    "    assert len(X_train_features) == len(filtered_Y_train_nodes), \"训练集特征和标签数量不一致！\"\n",
    "    assert len(X_test_features) == len(filtered_Y_test_nodes), \"测试集特征和标签数量不一致！\"\n",
    "\n",
    "    accuracies = []\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    model.fit(X_train_features, Y_train_nodes)\n",
    "    predictions = model.predict(X_test_features)\n",
    "\n",
    "    accuracies.append(accuracy_score(Y_test_nodes, predictions))\n",
    "\n",
    "    print(\"Average Accuracy:\", sum(accuracies) / len(accuracies))\n",
    "\n",
    "\n"
   ],
   "id": "8d4853493c554e58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfs_walks完成！\n",
      "嵌入模型训练完成！\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "训练集特征和标签数量不一致！",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 95\u001B[0m\n\u001B[1;32m     92\u001B[0m X_test_features \u001B[38;5;241m=\u001B[39m extract_features(CBOW_embedding_model, filtered_X_test_nodes)\n\u001B[1;32m     93\u001B[0m Y_test_features \u001B[38;5;241m=\u001B[39m extract_features(CBOW_embedding_model, filtered_Y_test_nodes)\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(X_train_features) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(filtered_Y_train_nodes), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m训练集特征和标签数量不一致！\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(X_test_features) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(filtered_Y_test_nodes), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m测试集特征和标签数量不一致！\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     98\u001B[0m accuracies \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mAssertionError\u001B[0m: 训练集特征和标签数量不一致！"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ed3865e25fe34c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.626740Z",
     "start_time": "2025-01-31T10:55:59.888202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 生成广度优先路径序列\n",
    "bfs_walks = generate_graph_walks(graphs, depth=8)\n",
    "print(\"广度优先路径序列生成完成！\")"
   ],
   "id": "a58bc6d066241318",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广度优先路径序列生成完成！\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.627027Z",
     "start_time": "2025-01-31T10:55:59.921399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 生成 Weisfeiler-Lehman 子树路径序列\n",
    "wl_walks = generate_wl_subtree_walks(graphs, iterations=4, depth=2)\n",
    "print(\"Weisfeiler-Lehman 子树路径序列生成完成！\")"
   ],
   "id": "10c6cac37cd3c2d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weisfeiler-Lehman 子树路径序列生成完成！\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.627195Z",
     "start_time": "2025-01-31T10:55:59.941685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "for train_index, test_index in kf.split(nodes):\n",
    "\n",
    "        X_train, X_test = [bfs_walks[i] for i in train_index], [bfs_walks[i] for i in test_index]\n",
    "        bfs_walks = generate_graph_walks(X_train, depth=8)\n",
    "        CBOW_embedding_model = train_word2vec(bfs_walks, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "        print(\"嵌入模型训练完成！\")\n",
    "\n",
    "        nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "        features = extract_features(CBOW_embedding_model, nodes)\n"
   ],
   "id": "9755050d69b36ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n",
      "嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.631626Z",
     "start_time": "2025-01-31T10:56:06.364762Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "221e97b5a55cadd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.632135Z",
     "start_time": "2025-01-31T10:56:06.379073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练嵌入模型\n",
    "CBOW_embedding_model = train_word2vec(X_train, dimensions=200, window_size=5, sg=0, negative=25)\n",
    "print(\"嵌入模型训练完成！\")"
   ],
   "id": "c2a8ae3211a68826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.641369Z",
     "start_time": "2025-01-31T10:56:07.015842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练 Skip-gram 嵌入模型\n",
    "SG_embedding_model = train_skipgram_model(bfs_walks, dimensions=200, window_size=5, sg=1, negative=25)\n",
    "print(\"Skip-gram 嵌入模型训练完成！\")"
   ],
   "id": "76f0cfed136c65d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip-gram 嵌入模型训练完成！\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.643717Z",
     "start_time": "2025-01-31T10:56:08.570380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 提取嵌入特征\n",
    "nodes = [str(node) for graph in graphs for node in graph.all_nodes()]\n",
    "features = extract_features(SG_embedding_model, nodes)\n",
    "print(\"嵌入特征提取完成！\")"
   ],
   "id": "6bd182251e39fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嵌入特征提取完成！\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-03T15:04:39.655698Z",
     "start_time": "2025-01-31T10:56:08.584064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 评估分类任务\n",
    "labels = {\"node1\": 0, \"node2\": 1}  # 替换为你的节点标签\n",
    "evaluate_features(features, labels, task=\"classification\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
